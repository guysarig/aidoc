## Overview
This project implements a serverless ordering system using AWS services to handle order validation and processing. The solution leverages S3, DynamoDB, SQS, and Lambda, with an API Gateway to expose a secure HTTP endpoint for retrieving processed orders. Terraform is used for infrastructure as code to automate resource provisioning and configuration.

---

## Steps to Use the Project Functions

### 1. **Set Up the Destination Bucket**
   - Create an `orders` folder (key) in the destination S3 bucket. This is where order files will be uploaded for processing.
   - Example command:
     ```bash
     aws s3api put-object --bucket <destination-bucket> --key orders/
     ```

### 2. **Populate the Database with a Sample Record**
   - Navigate to the `sample_data` folder and run the script `create_db_row.sh` to create a sample order record in DynamoDB.
   - Command:
     ```bash
     sh ./sample_data/create_db_row.sh
     ```

### 3. **Upload a Sample Order File**
   - Upload the `order123456.json` file (located in the `sample_data` folder) to the `orders` key in the destination bucket.
   - Command:
     ```bash
     aws s3 cp sample_data/order123456.json s3://<destination-bucket>/orders/
     ```

### 4. **Process the Order from the Queue**
   - After a few seconds, when the order is validated, a message will appear in the SQS queue.
   - Retrieve and process the order using the `/process` HTTP endpoint.
   - Navigate to the project root and execute:
     ```bash
     sh ./curl_process_order.sh
     ```
   - The script will use the API key generated by Terraform to authenticate and send a request to the `/process` endpoint, retrieving the order details.

---

## Notes
- The API key required for `/process` is dynamically generated by Terraform and passed securely to the Lambda function. Ensure you retrieve this key after deployment.
- All scripts assume AWS CLI is configured with proper credentials and permissions to interact with the AWS account.
"""